{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24709203-0a58-47be-99dc-1d3804c6f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA PIPELINE (Standardize + Validate + Output) — pathlib version\n",
    "---------------------------------------------------------------------\n",
    "Architecture:\n",
    "load_data → standardize_data → run_validations\n",
    "   ├─ if ERROR → export DQ report + STOP\n",
    "   └─ if OK/WARN → export DQ report + export clean dataset\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "\n",
    "INPUT_FILE = Path(\"data\") / \"finance_data.csv\"\n",
    "\n",
    "OUTPUT_FOLDER = Path(\"output\")\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DQ_REPORT_CSV = OUTPUT_FOLDER / \"dq_report.csv\"\n",
    "DQ_REPORT_XLSX = OUTPUT_FOLDER / \"dq_report.xlsx\"\n",
    "\n",
    "CLEAN_DATASET_CSV = OUTPUT_FOLDER / \"finance_clean.csv\"\n",
    "CLEAN_DATASET_XLSX = OUTPUT_FOLDER / \"finance_clean.xlsx\"\n",
    "\n",
    "REQUIRED_COLUMNS = [\"date\", \"account\", \"cost_center\", \"entity\", \"scenario\", \"amount\"]\n",
    "KEY_COLUMNS = [\"date\", \"account\", \"cost_center\", \"entity\", \"scenario\"]\n",
    "\n",
    "ALLOWED_SCENARIOS = {\"Actual\", \"Budget\", \"Forecast\"}\n",
    "VARIANCE_THRESHOLD = 0.30  # 30% MoM threshold -> WARNING\n",
    "\n",
    "\n",
    "# ============================\n",
    "# LOAD\n",
    "# ============================\n",
    "\n",
    "def load_data(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV into DataFrame and parse 'date' as datetime.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {file_path}\")\n",
    "    return pd.read_csv(file_path, parse_dates=[\"date\"])\n",
    "\n",
    "\n",
    "# ============================\n",
    "# STANDARDIZE (safe cleanup)\n",
    "# ============================\n",
    "\n",
    "def standardize_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Safe, mechanical standardization:\n",
    "    - trim text columns\n",
    "    - normalize scenario values\n",
    "    - coerce amount to numeric\n",
    "    - drop fully empty rows\n",
    "    Note: does NOT \"fix\" business issues like missing keys.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Trim whitespace in key text columns (prevents false mismatches)\n",
    "    for col in [\"account\", \"cost_center\", \"entity\", \"scenario\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "    # Normalize scenario variants -> canonical names\n",
    "    scenario_map = {\n",
    "        \"actual\": \"Actual\", \"act\": \"Actual\",\n",
    "        \"budget\": \"Budget\", \"bud\": \"Budget\",\n",
    "        \"forecast\": \"Forecast\", \"fc\": \"Forecast\", \"fcast\": \"Forecast\",\n",
    "    }\n",
    "    if \"scenario\" in df.columns:\n",
    "        df[\"scenario\"] = (\n",
    "            df[\"scenario\"]\n",
    "            .str.lower()\n",
    "            .map(scenario_map)\n",
    "            .fillna(df[\"scenario\"])\n",
    "        )\n",
    "\n",
    "    # Amount as numeric; invalid values become NaN (caught in validations)\n",
    "    if \"amount\" in df.columns:\n",
    "        df[\"amount\"] = pd.to_numeric(df[\"amount\"], errors=\"coerce\")\n",
    "\n",
    "    # Safe cleanup: remove fully empty rows\n",
    "    df = df.dropna(how=\"all\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================\n",
    "# VALIDATIONS (quality gates)\n",
    "# ============================\n",
    "\n",
    "def _issue(check_type: str, severity: str, description: str, value) -> dict:\n",
    "    \"\"\"Uniform schema for DQ report rows.\"\"\"\n",
    "    return {\n",
    "        \"check_type\": check_type,      # e.g. SCHEMA_MISSING_COLUMNS\n",
    "        \"severity\": severity,          # OK / WARNING / ERROR\n",
    "        \"description\": description,    # human-friendly message\n",
    "        \"value\": value,               # numeric (count/ratio/amount/etc.)\n",
    "    }\n",
    "\n",
    "\n",
    "def check_schema(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Required columns must exist (ERROR). Extra columns are usually WARNING.\"\"\"\n",
    "    issues = []\n",
    "    expected = set(REQUIRED_COLUMNS)\n",
    "    actual = set(df.columns)\n",
    "\n",
    "    missing = expected - actual\n",
    "    extra = actual - expected\n",
    "\n",
    "    if missing:\n",
    "        issues.append(_issue(\n",
    "            \"SCHEMA_MISSING_COLUMNS\",\n",
    "            \"ERROR\",\n",
    "            f\"Missing required columns: {', '.join(sorted(missing))}\",\n",
    "            len(missing),\n",
    "        ))\n",
    "\n",
    "    if extra:\n",
    "        issues.append(_issue(\n",
    "            \"SCHEMA_EXTRA_COLUMNS\",\n",
    "            \"WARNING\",\n",
    "            f\"Unexpected extra columns detected: {', '.join(sorted(extra))}\",\n",
    "            len(extra),\n",
    "        ))\n",
    "\n",
    "    return pd.DataFrame(issues)\n",
    "\n",
    "\n",
    "def check_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Missing values in required columns (ERROR).\"\"\"\n",
    "    issues = []\n",
    "    for col in REQUIRED_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        missing_count = int(df[col].isna().sum())\n",
    "        if missing_count > 0:\n",
    "            issues.append(_issue(\n",
    "                \"MISSING_VALUES\",\n",
    "                \"ERROR\",\n",
    "                f\"Missing values in column '{col}'\",\n",
    "                missing_count,\n",
    "            ))\n",
    "    return pd.DataFrame(issues)\n",
    "\n",
    "\n",
    "def check_scenarios(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Scenario values must be known (ERROR).\"\"\"\n",
    "    issues = []\n",
    "    if \"scenario\" not in df.columns:\n",
    "        return pd.DataFrame(issues)\n",
    "\n",
    "    unknown = set(df[\"scenario\"].dropna().unique()) - ALLOWED_SCENARIOS\n",
    "    if unknown:\n",
    "        issues.append(_issue(\n",
    "            \"SCENARIO_UNKNOWN\",\n",
    "            \"ERROR\",\n",
    "            f\"Unknown scenario values: {', '.join(sorted(map(str, unknown)))}\",\n",
    "            len(unknown),\n",
    "        ))\n",
    "    return pd.DataFrame(issues)\n",
    "\n",
    "\n",
    "def check_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Fully identical duplicates (WARNING)\n",
    "    - Duplicates by business key (ERROR)\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "\n",
    "    # Fully identical duplicates (informational)\n",
    "    before = len(df)\n",
    "    after = len(df.drop_duplicates())\n",
    "    removed = before - after\n",
    "    if removed > 0:\n",
    "        issues.append(_issue(\n",
    "            \"DUPLICATES_IDENTICAL\",\n",
    "            \"WARNING\",\n",
    "            \"Fully identical duplicate rows detected (review upstream process)\",\n",
    "            int(removed),\n",
    "        ))\n",
    "\n",
    "    # Duplicates by business key (ambiguous truth)\n",
    "    if all(col in df.columns for col in KEY_COLUMNS):\n",
    "        dup_by_key = int(df.duplicated(subset=KEY_COLUMNS, keep=False).sum())\n",
    "        if dup_by_key > 0:\n",
    "            issues.append(_issue(\n",
    "                \"DUPLICATES_BY_KEY\",\n",
    "                \"ERROR\",\n",
    "                \"Duplicate records detected for the same business key (Date+Account+CostCenter+Entity+Scenario)\",\n",
    "                dup_by_key,\n",
    "            ))\n",
    "\n",
    "    return pd.DataFrame(issues)\n",
    "\n",
    "\n",
    "def check_control_totals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Basic control totals per scenario.\n",
    "    - Missing scenario (ERROR)\n",
    "    - Total NaN (ERROR)\n",
    "    - Total == 0 (WARNING; might be valid, depends on context)\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    if \"scenario\" not in df.columns or \"amount\" not in df.columns:\n",
    "        return pd.DataFrame(issues)\n",
    "\n",
    "    totals = df.groupby(\"scenario\")[\"amount\"].sum(min_count=1)\n",
    "\n",
    "    for scenario in ALLOWED_SCENARIOS:\n",
    "        if scenario not in totals.index:\n",
    "            issues.append(_issue(\n",
    "                \"CONTROL_TOTAL_MISSING_SCENARIO\",\n",
    "                \"ERROR\",\n",
    "                f\"Scenario '{scenario}' missing in dataset\",\n",
    "                1,\n",
    "            ))\n",
    "            continue\n",
    "\n",
    "        total = totals.loc[scenario]\n",
    "        if pd.isna(total):\n",
    "            issues.append(_issue(\n",
    "                \"CONTROL_TOTAL_NAN\",\n",
    "                \"ERROR\",\n",
    "                f\"Scenario '{scenario}' total is NaN (likely invalid amounts)\",\n",
    "                1,\n",
    "            ))\n",
    "        elif float(total) == 0.0:\n",
    "            issues.append(_issue(\n",
    "                \"CONTROL_TOTAL_ZERO\",\n",
    "                \"WARNING\",\n",
    "                f\"Scenario '{scenario}' total equals 0 (verify if expected)\",\n",
    "                0,\n",
    "            ))\n",
    "\n",
    "    return pd.DataFrame(issues)\n",
    "\n",
    "\n",
    "def check_monthly_anomalies(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Flag large Month-over-Month changes per scenario (WARNING).\"\"\"\n",
    "    if not {\"date\", \"scenario\", \"amount\"}.issubset(df.columns):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    monthly = (\n",
    "        df.sort_values(\"date\")\n",
    "          .groupby([pd.Grouper(key=\"date\", freq=\"M\"), \"scenario\"])[\"amount\"]\n",
    "          .sum()\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    monthly[\"prev_amount\"] = monthly.groupby(\"scenario\")[\"amount\"].shift(1)\n",
    "    monthly[\"change_pct\"] = (monthly[\"amount\"] - monthly[\"prev_amount\"]) / monthly[\"prev_amount\"].abs()\n",
    "\n",
    "    anomalies = monthly[monthly[\"change_pct\"].abs() > VARIANCE_THRESHOLD].copy()\n",
    "    if anomalies.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"check_type\": \"MONTHLY_ANOMALY\",\n",
    "        \"severity\": \"WARNING\",\n",
    "        \"description\": (\n",
    "            \"High MoM change in \"\n",
    "            + anomalies[\"scenario\"].astype(str)\n",
    "            + \" for \"\n",
    "            + anomalies[\"date\"].dt.strftime(\"%Y-%m\")\n",
    "        ),\n",
    "        \"value\": anomalies[\"change_pct\"].round(2),\n",
    "    })\n",
    "\n",
    "\n",
    "def run_validations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run checks and return a unified DQ report.\n",
    "    Schema check first; if it has ERROR, skip deeper checks.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "\n",
    "    schema_issues = check_schema(df)\n",
    "    frames.append(schema_issues)\n",
    "\n",
    "    if not schema_issues.empty and (schema_issues[\"severity\"] == \"ERROR\").any():\n",
    "        return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    frames.extend([\n",
    "        check_scenarios(df),\n",
    "        check_missing_values(df),\n",
    "        check_duplicates(df),\n",
    "        check_control_totals(df),\n",
    "        check_monthly_anomalies(df),\n",
    "    ])\n",
    "\n",
    "    report = pd.concat(frames, ignore_index=True)\n",
    "    if report.empty:\n",
    "        report = pd.DataFrame([_issue(\"ALL_CHECKS\", \"OK\", \"No data quality issues detected\", 0)])\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def has_errors(report_df: pd.DataFrame) -> bool:\n",
    "    \"\"\"True if DQ report contains any ERROR.\"\"\"\n",
    "    return (not report_df.empty) and (\"severity\" in report_df.columns) and (report_df[\"severity\"] == \"ERROR\").any()\n",
    "\n",
    "\n",
    "# ============================\n",
    "# OUTPUT\n",
    "# ============================\n",
    "\n",
    "def export_dq_report(report_df: pd.DataFrame) -> None:\n",
    "    \"\"\"Export DQ report to CSV and Excel.\"\"\"\n",
    "    report_df.to_csv(DQ_REPORT_CSV, index=False)\n",
    "    report_df.to_excel(DQ_REPORT_XLSX, index=False)\n",
    "\n",
    "\n",
    "def export_clean_dataset(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Export standardized (clean) dataset to CSV and Excel.\"\"\"\n",
    "    df.to_csv(CLEAN_DATASET_CSV, index=False)\n",
    "    df.to_excel(CLEAN_DATASET_XLSX, index=False)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ENTRY POINT\n",
    "# ============================\n",
    "\n",
    "def main() -> int:\n",
    "    # 1) Load\n",
    "    df_raw = load_data(INPUT_FILE)\n",
    "\n",
    "    # 2) Standardize\n",
    "    df_std = standardize_data(df_raw)\n",
    "\n",
    "    # 3) Validate\n",
    "    dq_report = run_validations(df_std)\n",
    "\n",
    "    # 4) Always export DQ report\n",
    "    export_dq_report(dq_report)\n",
    "\n",
    "    # 5) Stop on ERROR; else export clean dataset\n",
    "    if has_errors(dq_report):\n",
    "        print(f\"DQ FAILED (ERROR). Report exported to: {DQ_REPORT_XLSX}\")\n",
    "        print(\"Clean dataset NOT exported.\")\n",
    "        return 1\n",
    "\n",
    "    export_clean_dataset(df_std)\n",
    "    print(f\"DQ PASSED (OK/WARN). DQ report: {DQ_REPORT_XLSX}\")\n",
    "    print(f\"Clean dataset exported to: {CLEAN_DATASET_CSV} and {CLEAN_DATASET_XLSX}\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sys.exit(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
